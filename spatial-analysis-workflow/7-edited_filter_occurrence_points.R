################################################################################
# Load libraries
################################################################################

# load packages
my.packages <- c('tidyverse','textclean','tools')
# versions I used (in the order listed above): 2.0.0, 0.9.3, 4.3.0
#install.packages (my.packages) #Turn on to install current versions
lapply(my.packages, require, character.only=TRUE)
rm(my.packages)

################################################################################
# Set working directory
################################################################################

# create folder for output data
data_out <- "taxon_points_final"
if(!dir.exists(file.path(standard_occ,data_out)))
  dir.create(file.path(standard_occ,data_out), 
             recursive=T)

# assign folder where you have input data (saved in 5-flag_occurrence_points.R)
data_in <- "taxon_points_ready-to-vet_original"

################################################################################
# Filter occurrence points by flags from script #5 and any manual edits in
#   manual_point_edits.R file
################################################################################

# read in manual point edits file
manual_edits <- read.csv(file.path(standard_occ,
                                   "original_manual_point_edits.csv"),
                         header=T, colClasses="character", na.strings=c("","NA"))
# remove all spaces in the manual edits, to standardize in case manual mistakes
manual_edits <- manual_edits %>%
  mutate(across(remove_id:keep_id, ~
                  str_remove_all(.x, pattern = fixed(" "))))
manual_edits

# list of taxon files to iterate through
taxon_files <- list.files(path=file.path(standard_occ,data_in), 
                          ignore.case=FALSE, full.names=FALSE, recursive=TRUE)
target_taxa <- file_path_sans_ext(taxon_files)

# start a table to add summary of results for each species
summary_tbl <- data.frame(taxon_name_accepted = "start", final_pts = "start")

# cycle through each target taxon to remove flagged points and save new version
for (i in 1:length(target_taxa)){
  
  taxon_file <- target_taxa[i]
  taxon_nm <- mgsub(taxon_file, c("_","_var_","_subsp_"), 
                    c(" "," var. "," subsp. "))
  
  cat("Starting ", taxon_nm, ", ", i, " of ", length(target_taxa), "\n", sep="")
  
  ## read in records
  taxon_now <- read.csv(file.path(standard_occ,data_in,
                                  paste0(taxon_file, ".csv")))
  orig_num_pts <- nrow(taxon_now)
  # make sure all the T/F columns are logical type
  taxon_now <- taxon_now %>% mutate(across(.cen, as.logical))
  
  
  ## filter occurrence data based on filter columns created in 5-flag_occurrence_points.R
  taxon_now <- taxon_now %>%
    filter(
      # we keep all ex situ points even if flagged, so they must be manually
      #   selected for removal if bad
      database == "Ex_situ" |
        # choose which filters you want to use: comment out those you want to skip
        .cen & 
        .inst & 
        .outl &
        .con & 
        #.urb & 
        .nativectry &
       # .yr1950 & 
        #.yr1980 & 
        #.yrna &
        #.unc &
        .elev 
      #  .rec
    )
  cat(paste0("--Removed ",orig_num_pts-nrow(taxon_now)," points based on flagging colums\n"))
  
  
  ## check document with manual point edits to see if anything needs to be
  ##    removed or added back in
  # get manual edits row for the current target taxon
  taxon_edits <- manual_edits[which(
    manual_edits$taxon_name_accepted == taxon_nm),]
  # remove if ID listed in remove_id
  if(!is.na(taxon_edits$remove_id)){
    remove <- unlist(strsplit(taxon_edits$remove_id,";"))
    taxon_now <- taxon_now %>% filter(!(UID %in% remove))
    cat(paste0("--Removed ",length(remove)," points based on IDs to remove\n"))
  }
  # remove if inside remove_bounding_box
  if(!is.na(taxon_edits$remove_bounding_box)){
    boxes <- unlist(strsplit(taxon_edits$remove_bounding_box,";"))
    for(j in 1:length(boxes)){
      bounds <- unlist(strsplit(boxes[j],","))
      # note that if your bounding box crosses longitude 180/-180, which is near
      #   the international date line, then the longitude comparison here won't 
      #   work! - the filter would need to be edited to catch that exception
      remove <- taxon_now %>%
        filter(decimalLatitude < as.numeric(bounds[1]) & 
                 decimalLongitude > as.numeric(bounds[2]) &
                 decimalLatitude > as.numeric(bounds[3]) &
                 decimalLongitude < as.numeric(bounds[4]))
      taxon_now <- taxon_now %>%
        filter(!(UID %in% unique(remove$UID)))
      cat(paste0("--Removed ",nrow(remove)," points based on bounding box ", j,"\n"))
    }
  }
  # add back if ID listed in keep_id
  if(!is.na(taxon_edits$keep)){
    keep <- unlist(strsplit(taxon_edits$keep,";"))
    add <- taxon_now %>% filter(UID %in% keep)
    taxon_now <- suppressMessages(full_join(taxon_now,add))
    cat(paste0("--Added back ",length(keep)," points based on IDs to keep\n"))
  }
  
  ## write final occurrence point file
  write.csv(taxon_now, file.path(standard_occ,data_out,
                                 paste0(taxon_file,".csv")), 
            row.names=FALSE)
  
  # add data to summary table
  summary_add <- data.frame(
    taxon_name_accepted = taxon_nm,
    final_pts = nrow(taxon_now))
  summary_tbl[i,] <- summary_add
  
  ## cat update
  cat("Original points: ", orig_num_pts, "\n", sep="")
  cat("Final points: ", nrow(taxon_now), "\n\n", sep="")
  
}

# add summary of points to summary we created in 5-compile_occurrence_points.R
file_nm <- list.files(path = file.path(standard_occ),
                      pattern = "original_summary_of_occurrences", full.names = T)
orig_summary <- read.csv(file_nm, colClasses = "character")
# keep just the columns from script 5 output, in case you're running this script a second time
orig_summary <- orig_summary %>% select(taxon_name_accepted:.rec)
summary_tbl2 <- full_join(orig_summary,summary_tbl,by="taxon_name_accepted")
summary_tbl2

# write summary table
write.csv(summary_tbl2, file.path(standard_occ,
                                  paste0("original_summary_of_occurrences_", Sys.Date(), ".csv")),row.names = F)
